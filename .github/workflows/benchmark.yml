name: Performance Benchmarks

on:
  # Executa semanalmente Ã s segundas-feiras Ã s 02:00 UTC
  schedule:
    - cron: '0 2 * * 1'
  # Permite execuÃ§Ã£o manual
  workflow_dispatch:
    inputs:
      benchmark_filter:
        description: 'Filtro para benchmarks especÃ­ficos (opcional)'
        required: false
        default: ''
      iterations:
        description: 'NÃºmero de iteraÃ§Ãµes para cada benchmark'
        required: false
        default: '10'

env:
  VCPKG_BINARY_SOURCES: "clear;x-gha,readwrite"

jobs:
  benchmark:
    name: Run Performance Benchmarks
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        include:
          - os: ubuntu-latest
            compiler_cc: gcc-14
            compiler_cxx: g++-14
            generator: Ninja
            executable: ./lockfree_benchmark
          - os: windows-latest
            generator: "Visual Studio 17 2022"
            arch: x64
            executable: .\lockfree_benchmark.exe
          - os: macos-latest
            generator: Ninja
            executable: ./lockfree_benchmark
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        # Adicionar repositÃ³rio para GCC 14
        sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y
        sudo apt-get update
        sudo apt-get install -y gcc-14 g++-14 ninja-build
    
    - name: Install dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: brew install ninja
    
    - name: Export GitHub Actions cache environment variables
      uses: actions/github-script@v7
      with:
        script: |
          core.exportVariable('ACTIONS_CACHE_URL', process.env.ACTIONS_CACHE_URL || '');
          core.exportVariable('ACTIONS_RUNTIME_TOKEN', process.env.ACTIONS_RUNTIME_TOKEN || '');
    
    - name: Setup vcpkg
      uses: lukka/run-vcpkg@v11
      with:
        vcpkgGitCommitId: 'a42af01b72c28a8e1d7b48107b33e4f286a55ef6'
    
    - name: Configure CMake (Ubuntu/macOS)
      if: matrix.os != 'windows-latest'
      env:
        CC: ${{ matrix.compiler_cc }}
        CXX: ${{ matrix.compiler_cxx }}
      run: |
        cmake -B build -S . -G "${{ matrix.generator }}" \
          -DCMAKE_BUILD_TYPE=Release \
          -DCMAKE_C_COMPILER=${{ matrix.compiler_cc }} \
          -DCMAKE_CXX_COMPILER=${{ matrix.compiler_cxx }} \
          -DCMAKE_TOOLCHAIN_FILE=$VCPKG_ROOT/scripts/buildsystems/vcpkg.cmake
    
    - name: Configure CMake (Windows)
      if: matrix.os == 'windows-latest'
      run: |
        cmake -B build -S . -G "${{ matrix.generator }}" -A ${{ matrix.arch }} -DCMAKE_TOOLCHAIN_FILE=${{ github.workspace }}/vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE=Release
    
    - name: Build
      run: cmake --build build --config Release --parallel
    
    - name: Run Benchmarks - Pool Operations
      working-directory: build/bin
      run: |
        echo "=== Pool Operations Benchmarks ==="
        ${{ matrix.executable }} --benchmark_filter=".*Pool.*" --benchmark_repetitions=${{ github.event.inputs.iterations || '10' }} --benchmark_report_aggregates_only=true --benchmark_format=json --benchmark_out=pool_benchmarks.json
    
    - name: Run Benchmarks - Stress Tests
      working-directory: build/bin
      run: |
        echo "=== Stress Test Benchmarks ==="
        ${{ matrix.executable }} --benchmark_filter=".*Stress.*" --benchmark_repetitions=${{ github.event.inputs.iterations || '10' }} --benchmark_report_aggregates_only=true --benchmark_format=json --benchmark_out=stress_benchmarks.json
    
    - name: Run Benchmarks - Multithreaded
      working-directory: build/bin
      run: |
        echo "=== Multithreaded Benchmarks ==="
        ${{ matrix.executable }} --benchmark_filter=".*Multithread.*" --benchmark_repetitions=${{ github.event.inputs.iterations || '10' }} --benchmark_report_aggregates_only=true --benchmark_format=json --benchmark_out=multithread_benchmarks.json
    
    - name: Run Custom Filter Benchmarks
      if: github.event.inputs.benchmark_filter != ''
      working-directory: build/bin
      run: |
        echo "=== Custom Filter Benchmarks ==="
        ${{ matrix.executable }} --benchmark_filter="${{ github.event.inputs.benchmark_filter }}" --benchmark_repetitions=${{ github.event.inputs.iterations || '10' }} --benchmark_report_aggregates_only=true --benchmark_format=json --benchmark_out=custom_benchmarks.json
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ matrix.os }}
        path: |
          build/bin/*_benchmarks.json
        retention-days: 30
    
    - name: Generate benchmark summary
      working-directory: build/bin
      shell: bash
      run: |
        echo "# Benchmark Results Summary - ${{ matrix.os }}" > benchmark_summary.md
        echo "" >> benchmark_summary.md
        echo "## System Information" >> benchmark_summary.md
        echo "- OS: ${{ matrix.os }}" >> benchmark_summary.md
        echo "- Date: $(date)" >> benchmark_summary.md
        echo "- Iterations: ${{ github.event.inputs.iterations || '10' }}" >> benchmark_summary.md
        echo "" >> benchmark_summary.md
        
        # Processar resultados dos benchmarks se existirem
        for file in *_benchmarks.json; do
          if [ -f "$file" ]; then
            echo "## Results from $file" >> benchmark_summary.md
            echo "\`\`\`json" >> benchmark_summary.md
            head -20 "$file" >> benchmark_summary.md
            echo "\`\`\`" >> benchmark_summary.md
            echo "" >> benchmark_summary.md
          fi
        done
    
    - name: Upload benchmark summary
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-summary-${{ matrix.os }}
        path: build/bin/benchmark_summary.md
        retention-days: 30

  # Job para consolidar resultados de todos os sistemas operacionais
  consolidate-results:
    name: Consolidate Benchmark Results
    needs: benchmark
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download all benchmark results
      uses: actions/download-artifact@v4
      with:
        path: benchmark-results
    
    - name: Create consolidated report
      run: |
        echo "# Consolidated Benchmark Report" > BENCHMARK_REPORT.md
        echo "" >> BENCHMARK_REPORT.md
        echo "Generated on: $(date)" >> BENCHMARK_REPORT.md
        echo "Workflow: ${{ github.workflow }}" >> BENCHMARK_REPORT.md
        echo "Run ID: ${{ github.run_id }}" >> BENCHMARK_REPORT.md
        echo "" >> BENCHMARK_REPORT.md
        
        # Adicionar sumÃ¡rios de cada OS
        for summary_dir in benchmark-results/benchmark-summary-*; do
          if [ -d "$summary_dir" ]; then
            echo "---" >> BENCHMARK_REPORT.md
            cat "$summary_dir/benchmark_summary.md" >> BENCHMARK_REPORT.md
            echo "" >> BENCHMARK_REPORT.md
          fi
        done
        
        # Listar todos os arquivos de resultado disponÃ­veis
        echo "## Available Result Files" >> BENCHMARK_REPORT.md
        find benchmark-results -name "*.json" -type f | while read file; do
          echo "- $file" >> BENCHMARK_REPORT.md
        done
    
    - name: Upload consolidated report
      uses: actions/upload-artifact@v4
      with:
        name: consolidated-benchmark-report
        path: BENCHMARK_REPORT.md
        retention-days: 90
    
    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('BENCHMARK_REPORT.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## ðŸ“Š Benchmark Results\n\n${report}`
          });